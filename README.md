This project is meant to test
if ollam handles long context.

To get accurate information of
token count, please refer below:

https://platform.openai.com/tokenizer